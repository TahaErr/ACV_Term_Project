{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "mount_file_id": "1r0u-TlLxj1SOcBroVzLbkQjc745xfN0y",
      "authorship_tag": "ABX9TyMpdx2xDDln6HSr0SqrJRAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TahaErr/ACV_Term_Project/blob/main/PPE_GNN_Preparation_Data_Split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTHSKkx2UfVb"
      },
      "outputs": [],
      "source": [
        "#Data save path from PPE_DATA FACTORY\n",
        "#DATASET_SAVE_DIR = '/content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byBm4dTpzXA_",
        "outputId": "1f3d2ccc-7bac-4c74-e94a-c339c139338d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.242-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.242-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.242 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, glob\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATA_DIR = \"/content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs\"\n",
        "\n",
        "# Edge type ids (ÖNCEKİ JSON ÜRETİM KODUNUZLA AYNI)\n",
        "EDGE_SELF_LOOP     = 0\n",
        "EDGE_WEAR_PPE      = 1\n",
        "EDGE_NEAR_MACHINE  = 2\n",
        "\n",
        "def safe_int(x, default=-1):\n",
        "    try:\n",
        "        return int(x)\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "def parse_one_graph(g):\n",
        "    \"\"\"\n",
        "    g: dict loaded from one JSON graph file\n",
        "    returns:\n",
        "      graph_row: one row per graph\n",
        "      person_rows: rows per person_state\n",
        "      machine_labels: list of machine label strings\n",
        "      unexpected_edge_ids: set of unexpected edge ids seen in this graph\n",
        "    \"\"\"\n",
        "    src = str(g.get(\"source_video\", \"unknown\"))\n",
        "    label = safe_int(g.get(\"label\", -1))\n",
        "    frame_id = safe_int(g.get(\"frame_id\", -1))\n",
        "\n",
        "    has_person = bool(g.get(\"has_person\", False))\n",
        "    num_persons = safe_int(g.get(\"num_persons\", 0))\n",
        "    num_machines = safe_int(g.get(\"num_machines\", 0))\n",
        "\n",
        "    # Machine subclasses: node_types üzerinden (en sağlam)\n",
        "    node_types = g.get(\"node_types\", [])\n",
        "    machine_labels = []\n",
        "    for nt in node_types:\n",
        "        if isinstance(nt, str) and nt.startswith(\"machine:\"):\n",
        "            machine_labels.append(nt.split(\"machine:\", 1)[1])\n",
        "\n",
        "    # Edge type distribution\n",
        "    et = g.get(\"edge_type\", [])\n",
        "    et_counter = Counter(et)\n",
        "\n",
        "    allowed_edge_ids = {EDGE_SELF_LOOP, EDGE_WEAR_PPE, EDGE_NEAR_MACHINE}\n",
        "    unexpected_edge_ids = set([e for e in et_counter.keys() if e not in allowed_edge_ids])\n",
        "\n",
        "    # Near edges ve proximity (edge_attr proximity)\n",
        "    near_edge_count = et_counter.get(EDGE_NEAR_MACHINE, 0)\n",
        "    edge_attr = g.get(\"edge_attr\", [])\n",
        "    near_prox_vals = []\n",
        "    if et and edge_attr and len(et) == len(edge_attr):\n",
        "        for t, a in zip(et, edge_attr):\n",
        "            if t == EDGE_NEAR_MACHINE:\n",
        "                try:\n",
        "                    near_prox_vals.append(float(a[0]))\n",
        "                except Exception:\n",
        "                    pass\n",
        "\n",
        "    avg_near_prox = (sum(near_prox_vals) / len(near_prox_vals)) if near_prox_vals else None\n",
        "\n",
        "    # Person states\n",
        "    ps = g.get(\"person_states\", [])\n",
        "    person_rows = []\n",
        "    for p in ps:\n",
        "        person_rows.append({\n",
        "            \"source_video\": src,\n",
        "            \"frame_id\": frame_id,\n",
        "            \"label\": label,\n",
        "            \"person_node_id\": safe_int(p.get(\"person_node_id\", -1)),\n",
        "            \"has_helmet\": bool(p.get(\"has_helmet\", False)),\n",
        "            \"has_vest\": bool(p.get(\"has_vest\", False)),\n",
        "            \"near_machine\": bool(p.get(\"near_machine\", False)),\n",
        "        })\n",
        "\n",
        "    graph_row = {\n",
        "        \"source_video\": src,\n",
        "        \"frame_id\": frame_id,\n",
        "        \"label\": label,\n",
        "        \"has_person\": has_person,\n",
        "        \"num_persons\": num_persons,\n",
        "        \"num_machines\": num_machines,\n",
        "        \"num_machine_types_in_graph\": len(set(machine_labels)),\n",
        "\n",
        "        # near edge stats\n",
        "        \"near_edge_count\": near_edge_count,\n",
        "        \"avg_near_proximity\": avg_near_prox,\n",
        "\n",
        "        # edge type counts (gloves yok)\n",
        "        \"edge_self\": et_counter.get(EDGE_SELF_LOOP, 0),\n",
        "        \"edge_wear_ppe\": et_counter.get(EDGE_WEAR_PPE, 0),\n",
        "        \"edge_near\": et_counter.get(EDGE_NEAR_MACHINE, 0),\n",
        "    }\n",
        "\n",
        "    return graph_row, person_rows, machine_labels, unexpected_edge_ids\n",
        "\n",
        "\n",
        "# --- Load all JSONs ---\n",
        "json_files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.json\")))\n",
        "print(\"Total JSON files:\", len(json_files))\n",
        "\n",
        "graph_rows = []\n",
        "person_rows_all = []\n",
        "machine_labels_all = []\n",
        "\n",
        "unexpected_edges_global = Counter()\n",
        "\n",
        "for fp in tqdm(json_files):\n",
        "    with open(fp, \"r\") as f:\n",
        "        g = json.load(f)\n",
        "\n",
        "    gr, pr, mlabels, unexpected = parse_one_graph(g)\n",
        "    graph_rows.append(gr)\n",
        "    person_rows_all.extend(pr)\n",
        "    machine_labels_all.extend([(gr[\"source_video\"], ml) for ml in mlabels])\n",
        "\n",
        "    for e in unexpected:\n",
        "        unexpected_edges_global[e] += 1\n",
        "\n",
        "graphs_df = pd.DataFrame(graph_rows)\n",
        "persons_df = pd.DataFrame(person_rows_all)\n",
        "machines_df = pd.DataFrame(machine_labels_all, columns=[\"source_video\", \"machine_label\"])\n",
        "\n",
        "print(\"graphs_df:\", graphs_df.shape, \"| persons_df:\", persons_df.shape, \"| machines_df:\", machines_df.shape)\n",
        "\n",
        "# --- Sanity: unexpected edge ids ---\n",
        "if len(unexpected_edges_global) > 0:\n",
        "    print(\"\\n[WARNING] Beklenmeyen edge_type id tespit edildi! (Bu yeni pipeline’a uymuyor olabilir)\")\n",
        "    print(dict(unexpected_edges_global))\n",
        "else:\n",
        "    print(\"\\nEdge type sanity OK: Sadece {0:self, 1:wear_ppe, 2:near_machine} kullanılmış.\")\n",
        "\n",
        "\n",
        "# --- 1) Label distribution per video + overall ---\n",
        "def label_table(df, by=\"source_video\"):\n",
        "    tab = (\n",
        "        df.groupby(by)[\"label\"]\n",
        "          .value_counts(dropna=False)\n",
        "          .unstack(fill_value=0)\n",
        "          .sort_index()\n",
        "    )\n",
        "    # Risk label logic halen 0..3 varsayımıyla raporluyoruz\n",
        "    for c in [0, 1, 2, 3]:\n",
        "        if c not in tab.columns:\n",
        "            tab[c] = 0\n",
        "    tab = tab[[0, 1, 2, 3]]\n",
        "    tab[\"total\"] = tab.sum(axis=1)\n",
        "\n",
        "    pct = tab[[0, 1, 2, 3]].div(tab[\"total\"], axis=0).round(4)\n",
        "    pct.columns = [f\"p{c}\" for c in pct.columns]\n",
        "    return pd.concat([tab, pct], axis=1)\n",
        "\n",
        "print(\"\\n=== Label distribution per video ===\")\n",
        "per_video_labels = label_table(graphs_df, by=\"source_video\")\n",
        "print(per_video_labels)\n",
        "\n",
        "print(\"\\n=== Label distribution overall ===\")\n",
        "overall_labels = graphs_df[\"label\"].value_counts().to_dict()\n",
        "print(overall_labels)\n",
        "\n",
        "\n",
        "# --- 2) Person PPE / near statistics per video + overall ---\n",
        "if len(persons_df) > 0:\n",
        "    persons_df[\"ppe_complete\"] = persons_df[\"has_helmet\"] & persons_df[\"has_vest\"]\n",
        "\n",
        "    per_video_person = persons_df.groupby(\"source_video\").agg(\n",
        "        persons=(\"person_node_id\", \"count\"),\n",
        "        helmet_rate=(\"has_helmet\", \"mean\"),\n",
        "        vest_rate=(\"has_vest\", \"mean\"),\n",
        "        ppe_complete_rate=(\"ppe_complete\", \"mean\"),\n",
        "        near_rate=(\"near_machine\", \"mean\"),\n",
        "    ).round(4)\n",
        "\n",
        "    print(\"\\n=== Person-level PPE/near stats per video ===\")\n",
        "    print(per_video_person)\n",
        "\n",
        "    overall_person = persons_df.agg(\n",
        "        persons=(\"person_node_id\", \"count\"),\n",
        "        helmet_rate=(\"has_helmet\", \"mean\"),\n",
        "        vest_rate=(\"has_vest\", \"mean\"),\n",
        "        ppe_complete_rate=(\"ppe_complete\", \"mean\"),\n",
        "        near_rate=(\"near_machine\", \"mean\"),\n",
        "    ).round(4)\n",
        "\n",
        "    print(\"\\n=== Person-level PPE/near stats overall ===\")\n",
        "    print(overall_person)\n",
        "else:\n",
        "    print(\"\\nNo person_states found in JSONs.\")\n",
        "\n",
        "\n",
        "# --- 3) Machine type diversity per video + overall ---\n",
        "if len(machines_df) > 0:\n",
        "    per_video_machine = (\n",
        "        machines_df.groupby(\"source_video\")[\"machine_label\"]\n",
        "        .value_counts()\n",
        "        .unstack(fill_value=0)\n",
        "        .sort_index()\n",
        "    )\n",
        "    per_video_machine[\"unique_machine_types\"] = (per_video_machine > 0).sum(axis=1)\n",
        "    per_video_machine[\"total_machine_nodes\"] = per_video_machine.drop(columns=[\"unique_machine_types\"]).sum(axis=1)\n",
        "\n",
        "    print(\"\\n=== Machine type counts per video ===\")\n",
        "    print(per_video_machine)\n",
        "\n",
        "    overall_machine_counts = machines_df[\"machine_label\"].value_counts()\n",
        "    print(\"\\n=== Machine type counts overall ===\")\n",
        "    print(overall_machine_counts.to_dict())\n",
        "else:\n",
        "    print(\"\\nNo machines found in JSONs.\")\n",
        "\n",
        "\n",
        "# --- 4) Edge type distribution per video + overall (graph-level aggregation) ---\n",
        "edge_cols = [\"edge_self\", \"edge_wear_ppe\", \"edge_near\"]\n",
        "per_video_edges = graphs_df.groupby(\"source_video\")[edge_cols].sum()\n",
        "per_video_edges[\"total_edges\"] = per_video_edges.sum(axis=1)\n",
        "\n",
        "print(\"\\n=== Edge type totals per video ===\")\n",
        "print(per_video_edges)\n",
        "\n",
        "overall_edges = graphs_df[edge_cols].sum().to_dict()\n",
        "overall_edges[\"total_edges\"] = sum(overall_edges.values())\n",
        "print(\"\\n=== Edge type totals overall ===\")\n",
        "print(overall_edges)\n",
        "\n",
        "\n",
        "# --- 5) Quick diversity checks ---\n",
        "MIN_GRAPHS_PER_VIDEO = 300\n",
        "MIN_LABEL_COUNT_PER_VIDEO = 30  # her label için, video bazında asgari örnek\n",
        "\n",
        "print(\"\\n=== Diversity Alerts (video bazında) ===\")\n",
        "alerts = []\n",
        "for vid, row in per_video_labels.iterrows():\n",
        "    total = int(row[\"total\"])\n",
        "    if total < MIN_GRAPHS_PER_VIDEO:\n",
        "        alerts.append((vid, f\"Graph sayısı düşük: {total} < {MIN_GRAPHS_PER_VIDEO}\"))\n",
        "    for lab in [0, 1, 2, 3]:\n",
        "        if int(row.get(lab, 0)) < MIN_LABEL_COUNT_PER_VIDEO:\n",
        "            alerts.append((vid, f\"Label {lab} az: {int(row.get(lab, 0))} < {MIN_LABEL_COUNT_PER_VIDEO}\"))\n",
        "\n",
        "if alerts:\n",
        "    for a in alerts:\n",
        "        print(f\"Video {a[0]}: {a[1]}\")\n",
        "else:\n",
        "    print(\"Alarm yok: video bazında temel dağılım eşikleri sağlanıyor.\")\n",
        "\n",
        "\n",
        "# --- 6) Save summaries (optional) ---\n",
        "summary_dir = os.path.join(DATA_DIR, \"_summaries\")\n",
        "os.makedirs(summary_dir, exist_ok=True)\n",
        "\n",
        "graphs_df.to_csv(os.path.join(summary_dir, \"graphs_summary.csv\"), index=False)\n",
        "persons_df.to_csv(os.path.join(summary_dir, \"persons_summary.csv\"), index=False)\n",
        "if len(machines_df) > 0:\n",
        "    machines_df.to_csv(os.path.join(summary_dir, \"machines_summary.csv\"), index=False)\n",
        "\n",
        "per_video_labels.to_csv(os.path.join(summary_dir, \"label_dist_per_video.csv\"))\n",
        "if len(persons_df) > 0:\n",
        "    per_video_person.to_csv(os.path.join(summary_dir, \"person_stats_per_video.csv\"))\n",
        "if len(machines_df) > 0:\n",
        "    per_video_machine.to_csv(os.path.join(summary_dir, \"machine_types_per_video.csv\"))\n",
        "per_video_edges.to_csv(os.path.join(summary_dir, \"edge_types_per_video.csv\"))\n",
        "\n",
        "print(\"\\nSaved summaries to:\", summary_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-akokAAUVqku",
        "outputId": "ba2fbb91-031a-4cd0-cf99-37df29052c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total JSON files: 6537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6537/6537 [02:05<00:00, 52.16it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "graphs_df: (6537, 12) | persons_df: (11782, 7) | machines_df: (7579, 2)\n",
            "\n",
            "Edge type sanity OK: Sadece {0:self, 1:wear_ppe, 2:near_machine} kullanılmış.\n",
            "\n",
            "=== Label distribution per video ===\n",
            "                 0     1   2    3  total      p0      p1      p2      p3\n",
            "source_video                                                            \n",
            "1               68   302   2   36    408  0.1667  0.7402  0.0049  0.0882\n",
            "2             1030   478   5  794   2307  0.4465  0.2072  0.0022  0.3442\n",
            "3               86   361   5   71    523  0.1644  0.6902  0.0096  0.1358\n",
            "4               57   273   2  156    488  0.1168  0.5594  0.0041  0.3197\n",
            "5              181   274   1   91    547  0.3309  0.5009  0.0018  0.1664\n",
            "6              255  1028  53  188   1524  0.1673  0.6745  0.0348  0.1234\n",
            "7              272   249   0  219    740  0.3676  0.3365  0.0000  0.2959\n",
            "\n",
            "=== Label distribution overall ===\n",
            "{1: 2965, 0: 1949, 3: 1555, 2: 68}\n",
            "\n",
            "=== Person-level PPE/near stats per video ===\n",
            "              persons  helmet_rate  vest_rate  ppe_complete_rate  near_rate\n",
            "source_video                                                               \n",
            "1                 754       0.2401     0.3130             0.1764     0.0915\n",
            "2                2030       0.0724     0.1094             0.0251     0.5547\n",
            "3                 959       0.6528     0.0792             0.0448     0.1178\n",
            "4                1823       0.2946     0.3779             0.1437     0.2567\n",
            "5                 677       0.0207     0.1640             0.0044     0.2157\n",
            "6                4659       0.3793     0.5615             0.3217     0.1219\n",
            "7                 880       0.0193     0.1330             0.0023     0.4102\n",
            "\n",
            "=== Person-level PPE/near stats overall ===\n",
            "                   person_node_id  has_helmet  has_vest  ppe_complete  \\\n",
            "persons                   11782.0         NaN       NaN           NaN   \n",
            "helmet_rate                   NaN      0.2792       NaN           NaN   \n",
            "vest_rate                     NaN         NaN    0.3452           NaN   \n",
            "ppe_complete_rate             NaN         NaN       NaN        0.1692   \n",
            "near_rate                     NaN         NaN       NaN           NaN   \n",
            "\n",
            "                   near_machine  \n",
            "persons                     NaN  \n",
            "helmet_rate                 NaN  \n",
            "vest_rate                   NaN  \n",
            "ppe_complete_rate           NaN  \n",
            "near_rate                 0.242  \n",
            "\n",
            "=== Machine type counts per video ===\n",
            "machine_label  backhoe_loader  compactor  concrete_mixer_truck  dozer  \\\n",
            "source_video                                                            \n",
            "1                           3         21                     6      0   \n",
            "2                          21       1412                    42   1810   \n",
            "3                           3         13                    16      8   \n",
            "4                          14         39                   113     21   \n",
            "5                           4          8                    25      8   \n",
            "6                          14         44                   101      6   \n",
            "7                           5         30                    26    129   \n",
            "\n",
            "machine_label  dump_truck  excavator  grader  mobile_crane  tower_crane  \\\n",
            "source_video                                                              \n",
            "1                       5         19       2            20            3   \n",
            "2                     478         24     551            17            0   \n",
            "3                       3         84       1           112           14   \n",
            "4                       1         43      20            60            0   \n",
            "5                     246         26       3           145            0   \n",
            "6                      19         72       3           188           10   \n",
            "7                     143        528       2            70            1   \n",
            "\n",
            "machine_label  wheel_loader  unique_machine_types  total_machine_nodes  \n",
            "source_video                                                            \n",
            "1                        20                     9                   99  \n",
            "2                       612                     9                 4967  \n",
            "3                         7                    10                  261  \n",
            "4                        15                     9                  326  \n",
            "5                         8                     9                  473  \n",
            "6                        35                    10                  492  \n",
            "7                        27                    10                  961  \n",
            "\n",
            "=== Machine type counts overall ===\n",
            "{'dozer': 1982, 'compactor': 1567, 'dump_truck': 895, 'excavator': 796, 'wheel_loader': 724, 'mobile_crane': 612, 'grader': 582, 'concrete_mixer_truck': 329, 'backhoe_loader': 64, 'tower_crane': 28}\n",
            "\n",
            "=== Edge type totals per video ===\n",
            "              edge_self  edge_wear_ppe  edge_near  total_edges\n",
            "source_video                                                  \n",
            "1                  1291            876        148         2315\n",
            "2                  7367            740       3718        11825\n",
            "3                  1976           1512        240         3728\n",
            "4                  3458           2618       1134         7210\n",
            "5                  1283            266        332         1881\n",
            "6                  9911           9520       1250        20681\n",
            "7                  1979            276       1000         3255\n",
            "\n",
            "=== Edge type totals overall ===\n",
            "{'edge_self': 27265, 'edge_wear_ppe': 15808, 'edge_near': 7822, 'total_edges': 50895}\n",
            "\n",
            "=== Diversity Alerts (video bazında) ===\n",
            "Video 1: Label 2 az: 2 < 30\n",
            "Video 2: Label 2 az: 5 < 30\n",
            "Video 3: Label 2 az: 5 < 30\n",
            "Video 4: Label 2 az: 2 < 30\n",
            "Video 5: Label 2 az: 1 < 30\n",
            "Video 7: Label 2 az: 0 < 30\n",
            "\n",
            "Saved summaries to: /content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs/_summaries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kodun yaptığı iş, DATA_DIR içindeki frame graph JSON dosyalarınızı tarayıp, GNN eğitimi için “dosya yolu + etiket” bilgisini içeren bir manifest (indeks) CSV üretmektir. Ayrıca video bazında etiket dağılımlarını raporlayıp CSV’ye kaydeder."
      ],
      "metadata": {
        "id": "rkoxhe08J2iD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATA_DIR = \"/content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs\"\n",
        "OUT_DIR = os.path.join(DATA_DIR, \"_index_3class\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Yeni kural sistemine göre 3-class mapping (gloves yok)\n",
        "# raw label meanings (sizdeki risk mantığı):\n",
        "# 0: uzak + (helmet & vest var)\n",
        "# 1: uzak + (helmet veya vest eksik)\n",
        "# 2: yakın + (helmet & vest var)\n",
        "# 3: yakın + (helmet veya vest eksik)\n",
        "#\n",
        "# 3-class training:\n",
        "# 0 -> Safe\n",
        "# 1,2 -> Warning (ara seviye)\n",
        "# 3 -> Critical\n",
        "LABEL_MAP_3C = {0: 0, 1: 1, 2: 1, 3: 2}\n",
        "\n",
        "rows = []\n",
        "json_files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.json\")))\n",
        "print(\"Total JSON files found:\", len(json_files))\n",
        "\n",
        "for fp in tqdm(json_files):\n",
        "    with open(fp, \"r\") as f:\n",
        "        g = json.load(f)\n",
        "\n",
        "    y = int(g.get(\"label\", -1))\n",
        "    if y not in LABEL_MAP_3C:\n",
        "        continue  # beklenmeyen label'ları atla (safety)\n",
        "\n",
        "    rows.append({\n",
        "        \"path\": fp,\n",
        "        \"file\": os.path.basename(fp),\n",
        "        \"source_video\": str(g.get(\"source_video\", \"unknown\")),\n",
        "        \"frame_id\": int(g.get(\"frame_id\", -1)),\n",
        "        \"label_raw\": y,                 # {0,1,2,3}\n",
        "        \"label_3c\": LABEL_MAP_3C[y],    # {0,1,2}\n",
        "        \"has_person\": bool(g.get(\"has_person\", False)),\n",
        "        \"num_persons\": int(g.get(\"num_persons\", 0)),\n",
        "        \"num_machines\": int(g.get(\"num_machines\", 0)),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df = df.sort_values([\"source_video\", \"frame_id\"]).reset_index(drop=True)\n",
        "\n",
        "manifest_path = os.path.join(OUT_DIR, \"manifest_3class.csv\")\n",
        "df.to_csv(manifest_path, index=False)\n",
        "\n",
        "print(\"\\nSaved:\", manifest_path)\n",
        "print(\"\\nLabel raw distribution:\")\n",
        "print(df[\"label_raw\"].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nLabel 3-class distribution (train ids):\")\n",
        "print(df[\"label_3c\"].value_counts().sort_index())\n",
        "\n",
        "# --- Video bazında RAW label dağılımı (0..3) ---\n",
        "per_video_raw = (\n",
        "    df.groupby(\"source_video\")[\"label_raw\"]\n",
        "      .value_counts()\n",
        "      .unstack(fill_value=0)\n",
        "      .sort_index()\n",
        ")\n",
        "for c in [0, 1, 2, 3]:\n",
        "    if c not in per_video_raw.columns:\n",
        "        per_video_raw[c] = 0\n",
        "per_video_raw = per_video_raw[[0, 1, 2, 3]]\n",
        "per_video_raw[\"total\"] = per_video_raw.sum(axis=1)\n",
        "per_video_raw.to_csv(os.path.join(OUT_DIR, \"label_dist_per_video_raw.csv\"))\n",
        "\n",
        "print(\"\\nSaved:\", os.path.join(OUT_DIR, \"label_dist_per_video_raw.csv\"))\n",
        "\n",
        "# --- Video bazında 3-class label dağılımı (0..2) ---\n",
        "per_video_3c = (\n",
        "    df.groupby(\"source_video\")[\"label_3c\"]\n",
        "      .value_counts()\n",
        "      .unstack(fill_value=0)\n",
        "      .sort_index()\n",
        ")\n",
        "for c in [0, 1, 2]:\n",
        "    if c not in per_video_3c.columns:\n",
        "        per_video_3c[c] = 0\n",
        "per_video_3c = per_video_3c[[0, 1, 2]]\n",
        "per_video_3c[\"total\"] = per_video_3c.sum(axis=1)\n",
        "per_video_3c.to_csv(os.path.join(OUT_DIR, \"label_dist_per_video_3class.csv\"))\n",
        "\n",
        "print(\"\\nSaved:\", os.path.join(OUT_DIR, \"label_dist_per_video_3class.csv\"))\n",
        "\n",
        "# Colab çıktıları\n",
        "display(per_video_raw)\n",
        "display(per_video_3c)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 983
        },
        "id": "Eq-MXQeDXpUz",
        "outputId": "161c2200-287a-4319-aca5-bfd81c1306c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total JSON files found: 6537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6537/6537 [00:47<00:00, 137.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved: /content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs/_index_3class/manifest_3class.csv\n",
            "\n",
            "Label raw distribution:\n",
            "label_raw\n",
            "0    1949\n",
            "1    2965\n",
            "2      68\n",
            "3    1555\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Label 3-class distribution (train ids):\n",
            "label_3c\n",
            "0    1949\n",
            "1    3033\n",
            "2    1555\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Saved: /content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs/_index_3class/label_dist_per_video_raw.csv\n",
            "\n",
            "Saved: /content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs/_index_3class/label_dist_per_video_3class.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "label_raw        0     1   2    3  total\n",
              "source_video                            \n",
              "1               68   302   2   36    408\n",
              "2             1030   478   5  794   2307\n",
              "3               86   361   5   71    523\n",
              "4               57   273   2  156    488\n",
              "5              181   274   1   91    547\n",
              "6              255  1028  53  188   1524\n",
              "7              272   249   0  219    740"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a75809b-d519-498c-bf9b-132d8b1de14f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>label_raw</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source_video</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68</td>\n",
              "      <td>302</td>\n",
              "      <td>2</td>\n",
              "      <td>36</td>\n",
              "      <td>408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1030</td>\n",
              "      <td>478</td>\n",
              "      <td>5</td>\n",
              "      <td>794</td>\n",
              "      <td>2307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>86</td>\n",
              "      <td>361</td>\n",
              "      <td>5</td>\n",
              "      <td>71</td>\n",
              "      <td>523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>273</td>\n",
              "      <td>2</td>\n",
              "      <td>156</td>\n",
              "      <td>488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>181</td>\n",
              "      <td>274</td>\n",
              "      <td>1</td>\n",
              "      <td>91</td>\n",
              "      <td>547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>255</td>\n",
              "      <td>1028</td>\n",
              "      <td>53</td>\n",
              "      <td>188</td>\n",
              "      <td>1524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>272</td>\n",
              "      <td>249</td>\n",
              "      <td>0</td>\n",
              "      <td>219</td>\n",
              "      <td>740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a75809b-d519-498c-bf9b-132d8b1de14f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0a75809b-d519-498c-bf9b-132d8b1de14f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0a75809b-d519-498c-bf9b-132d8b1de14f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-335f20a0-7b27-4496-bd28-2bd90eb63e28\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-335f20a0-7b27-4496-bd28-2bd90eb63e28')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-335f20a0-7b27-4496-bd28-2bd90eb63e28 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_075e8cc9-28df-4f0e-ba73-ebd3cea373b9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('per_video_raw')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_075e8cc9-28df-4f0e-ba73-ebd3cea373b9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('per_video_raw');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "per_video_raw",
              "summary": "{\n  \"name\": \"per_video_raw\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"source_video\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"1\",\n          \"2\",\n          \"6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 342,\n        \"min\": 57,\n        \"max\": 1030,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          68,\n          1030,\n          255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 277,\n        \"min\": 249,\n        \"max\": 1028,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          302,\n          478,\n          1028\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 53,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 260,\n        \"min\": 36,\n        \"max\": 794,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          36,\n          794,\n          188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 714,\n        \"min\": 408,\n        \"max\": 2307,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          408,\n          2307,\n          1524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "label_3c         0     1    2  total\n",
              "source_video                        \n",
              "1               68   304   36    408\n",
              "2             1030   483  794   2307\n",
              "3               86   366   71    523\n",
              "4               57   275  156    488\n",
              "5              181   275   91    547\n",
              "6              255  1081  188   1524\n",
              "7              272   249  219    740"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-806626ce-144e-4cc3-80a4-464525e35524\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>label_3c</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>source_video</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>68</td>\n",
              "      <td>304</td>\n",
              "      <td>36</td>\n",
              "      <td>408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1030</td>\n",
              "      <td>483</td>\n",
              "      <td>794</td>\n",
              "      <td>2307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>86</td>\n",
              "      <td>366</td>\n",
              "      <td>71</td>\n",
              "      <td>523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>275</td>\n",
              "      <td>156</td>\n",
              "      <td>488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>181</td>\n",
              "      <td>275</td>\n",
              "      <td>91</td>\n",
              "      <td>547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>255</td>\n",
              "      <td>1081</td>\n",
              "      <td>188</td>\n",
              "      <td>1524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>272</td>\n",
              "      <td>249</td>\n",
              "      <td>219</td>\n",
              "      <td>740</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-806626ce-144e-4cc3-80a4-464525e35524')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-806626ce-144e-4cc3-80a4-464525e35524 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-806626ce-144e-4cc3-80a4-464525e35524');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1c8422bc-d5ea-414e-a034-3034fc8345f2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c8422bc-d5ea-414e-a034-3034fc8345f2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1c8422bc-d5ea-414e-a034-3034fc8345f2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_974b8371-59bb-4c14-aafe-9d83503fc789\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('per_video_3c')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_974b8371-59bb-4c14-aafe-9d83503fc789 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('per_video_3c');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "per_video_3c",
              "summary": "{\n  \"name\": \"per_video_3c\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"source_video\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"1\",\n          \"2\",\n          \"6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 342,\n        \"min\": 57,\n        \"max\": 1030,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          68,\n          1030,\n          255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 296,\n        \"min\": 249,\n        \"max\": 1081,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          304,\n          483,\n          249\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 260,\n        \"min\": 36,\n        \"max\": 794,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          36,\n          794,\n          188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 714,\n        \"min\": 408,\n        \"max\": 2307,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          408,\n          2307,\n          1524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Her video için dosya listesi üret (split kolaylaşır)\n",
        "lists_dir = os.path.join(OUT_DIR, \"by_video_lists\")\n",
        "os.makedirs(lists_dir, exist_ok=True)\n",
        "\n",
        "for vid, sub in df.groupby(\"source_video\"):\n",
        "    out_fp = os.path.join(lists_dir, f\"video_{vid}_files.txt\")\n",
        "    sub[\"path\"].to_csv(out_fp, index=False, header=False)\n",
        "\n",
        "print(\"Saved per-video file lists to:\", lists_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bEWAyWzXpYD",
        "outputId": "9b6cf9df-86da-4d1b-877c-5f391146ebb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved per-video file lists to: /content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs/_index_3class/by_video_lists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJ68si5cXpbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Paths (YENİ SİSTEM) ---\n",
        "DATA_DIR = \"/content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs\"\n",
        "INDEX_DIR = os.path.join(DATA_DIR, \"_index_3class\")\n",
        "manifest_path = os.path.join(INDEX_DIR, \"manifest_3class.csv\")\n",
        "\n",
        "OUT_SPLIT_DIR = os.path.join(INDEX_DIR, \"splits_chunked\")\n",
        "os.makedirs(OUT_SPLIT_DIR, exist_ok=True)\n",
        "\n",
        "# --- Split params ---\n",
        "train_ratio = 0.80\n",
        "val_ratio   = 0.10\n",
        "test_ratio  = 0.10\n",
        "\n",
        "chunk_size_graphs = 60    # ~60 seconds since you sample ~1 graph/sec\n",
        "gap_graphs = 3            # default buffer\n",
        "seed = 1337\n",
        "\n",
        "# --- Guarantees / thresholds ---\n",
        "MIN_CHUNKS_FOR_BOTH_EVAL = 3\n",
        "MIN_EVAL_SAMPLES_AFTER_GAP = 30\n",
        "PROTECT_SHORT_CHUNKS_FROM_EVAL = True\n",
        "\n",
        "# Optional (genelde faydalı): person olmayan graph'ları çıkar\n",
        "FILTER_NO_PERSON_GRAPHS = False  # True yaparsanız has_person==False satırları split'e girmez\n",
        "\n",
        "assert abs((train_ratio + val_ratio + test_ratio) - 1.0) < 1e-9, \"Ratios must sum to 1.0\"\n",
        "\n",
        "df = pd.read_csv(manifest_path)\n",
        "\n",
        "# Yeni 3-class şema:\n",
        "# label_raw: 0..3 (risk)\n",
        "# label_3c:  0..2  (0->0, 1/2->1, 3->2)\n",
        "assert set(df[\"label_3c\"].unique()).issubset({0, 1, 2}), df[\"label_3c\"].unique()\n",
        "\n",
        "# (Opsiyonel) person olmayan graph'ları çıkar\n",
        "if FILTER_NO_PERSON_GRAPHS:\n",
        "    df = df[df[\"has_person\"] == True].copy()\n",
        "\n",
        "# Ensure proper sorting inside each video\n",
        "df = df.sort_values([\"source_video\", \"frame_id\"]).reset_index(drop=True)\n",
        "\n",
        "# Create per-video sample index (0..N-1)\n",
        "df[\"sample_idx\"] = df.groupby(\"source_video\").cumcount()\n",
        "\n",
        "# Assign chunk id (contiguous blocks)\n",
        "df[\"chunk_id\"] = (df[\"sample_idx\"] // chunk_size_graphs).astype(int)\n",
        "\n",
        "# Position inside chunk (for gap trimming)\n",
        "df[\"pos_in_chunk\"] = (df[\"sample_idx\"] % chunk_size_graphs).astype(int)\n",
        "\n",
        "rng = np.random.default_rng(seed)\n",
        "\n",
        "# We'll assign chunk_ids to splits per video\n",
        "df[\"split\"] = None\n",
        "\n",
        "for vid, sub in df.groupby(\"source_video\", sort=False):\n",
        "    chunk_ids = np.array(sorted(sub[\"chunk_id\"].unique()))\n",
        "    n_chunks = len(chunk_ids)\n",
        "\n",
        "    # Chunk lengths (detect tail/short chunk)\n",
        "    chunk_len_map = sub.groupby(\"chunk_id\")[\"sample_idx\"].count().to_dict()\n",
        "    short_chunks = {cid for cid, clen in chunk_len_map.items() if clen < chunk_size_graphs}\n",
        "\n",
        "    # Shuffle chunk order (still keeps within-chunk contiguity)\n",
        "    rng.shuffle(chunk_ids)\n",
        "\n",
        "    # Base rounding\n",
        "    n_train = int(round(n_chunks * train_ratio))\n",
        "    n_val   = int(round(n_chunks * val_ratio))\n",
        "    n_test  = n_chunks - n_train - n_val\n",
        "\n",
        "    # Fix rare rounding issues\n",
        "    if n_test < 0:\n",
        "        n_test = 0\n",
        "        n_val  = max(0, n_chunks - n_train - n_test)\n",
        "\n",
        "    # Guarantee #1: ensure >=1 val and >=1 test chunk if enough chunks\n",
        "    if n_chunks >= MIN_CHUNKS_FOR_BOTH_EVAL:\n",
        "        if n_val == 0:\n",
        "            n_val = 1\n",
        "        if n_test == 0:\n",
        "            n_test = 1\n",
        "        n_train = n_chunks - n_val - n_test\n",
        "\n",
        "        # Ensure at least 1 train chunk as well\n",
        "        if n_train < 1:\n",
        "            while n_train < 1 and (n_val > 1 or n_test > 1):\n",
        "                if n_val >= n_test and n_val > 1:\n",
        "                    n_val -= 1\n",
        "                elif n_test > 1:\n",
        "                    n_test -= 1\n",
        "                n_train = n_chunks - n_val - n_test\n",
        "\n",
        "    train_chunks = set(chunk_ids[:n_train])\n",
        "    val_chunks   = set(chunk_ids[n_train:n_train + n_val])\n",
        "    test_chunks  = set(chunk_ids[n_train + n_val:])\n",
        "\n",
        "    # Protect short/tail chunk from val/test (keeps eval meaningful)\n",
        "    if PROTECT_SHORT_CHUNKS_FROM_EVAL and n_chunks >= MIN_CHUNKS_FOR_BOTH_EVAL and len(short_chunks) > 0:\n",
        "        def swap_short_from_eval(eval_set):\n",
        "            shorts_in_eval = eval_set & short_chunks\n",
        "            if not shorts_in_eval:\n",
        "                return\n",
        "            short_cid = next(iter(shorts_in_eval))\n",
        "\n",
        "            # find a good candidate from train (prefer full chunks)\n",
        "            candidates = list(train_chunks - short_chunks)\n",
        "            if not candidates:\n",
        "                return\n",
        "            candidate = max(candidates, key=lambda c: chunk_len_map.get(c, 0))\n",
        "\n",
        "            # swap\n",
        "            eval_set.remove(short_cid)\n",
        "            eval_set.add(candidate)\n",
        "            train_chunks.remove(candidate)\n",
        "            train_chunks.add(short_cid)\n",
        "\n",
        "        swap_short_from_eval(val_chunks)\n",
        "        swap_short_from_eval(test_chunks)\n",
        "\n",
        "    # Assign splits back to df\n",
        "    df.loc[sub.index[sub[\"chunk_id\"].isin(train_chunks)], \"split\"] = \"train\"\n",
        "    df.loc[sub.index[sub[\"chunk_id\"].isin(val_chunks)],   \"split\"] = \"val\"\n",
        "    df.loc[sub.index[sub[\"chunk_id\"].isin(test_chunks)],  \"split\"] = \"test\"\n",
        "\n",
        "# Final sanity: no null splits\n",
        "assert df[\"split\"].isna().sum() == 0, \"Some rows have no split.\"\n",
        "\n",
        "# --- Guarantee #2: adaptive gap per video (if eval drops too much after gap) ---\n",
        "df_pre_gap = df.copy()\n",
        "\n",
        "if gap_graphs > 0:\n",
        "    chunk_len = df.groupby([\"source_video\", \"chunk_id\"])[\"sample_idx\"].count().rename(\"chunk_len\")\n",
        "    df_gap = df.merge(chunk_len, on=[\"source_video\", \"chunk_id\"], how=\"left\")\n",
        "\n",
        "    # Keep only middle part of each chunk\n",
        "    keep = (df_gap[\"pos_in_chunk\"] >= gap_graphs) & (df_gap[\"pos_in_chunk\"] < (df_gap[\"chunk_len\"] - gap_graphs))\n",
        "    df_gap = df_gap[keep].copy()\n",
        "    df_gap.drop(columns=[\"chunk_len\"], inplace=True)\n",
        "\n",
        "    # Compute per-video eval sizes after gap\n",
        "    counts_gap = df_gap.groupby([\"source_video\", \"split\"]).size().unstack(fill_value=0)\n",
        "    for c in [\"train\", \"val\", \"test\"]:\n",
        "        if c not in counts_gap.columns:\n",
        "            counts_gap[c] = 0\n",
        "\n",
        "    bad_videos = counts_gap.index[\n",
        "        (counts_gap[\"val\"] < MIN_EVAL_SAMPLES_AFTER_GAP) | (counts_gap[\"test\"] < MIN_EVAL_SAMPLES_AFTER_GAP)\n",
        "    ].tolist()\n",
        "\n",
        "    # For those videos: use gap=0 (revert to pre-gap rows for that video)\n",
        "    if len(bad_videos) > 0:\n",
        "        df_good = df_gap[~df_gap[\"source_video\"].isin(bad_videos)].copy()\n",
        "        df_bad  = df_pre_gap[df_pre_gap[\"source_video\"].isin(bad_videos)].copy()\n",
        "        df = pd.concat([df_good, df_bad], ignore_index=True)\n",
        "    else:\n",
        "        df = df_gap\n",
        "\n",
        "# Keep deterministic order at the end (optional but nice)\n",
        "df = df.sort_values([\"source_video\", \"frame_id\"]).reset_index(drop=True)\n",
        "\n",
        "# --- Save split CSVs ---\n",
        "train_df = df[df[\"split\"] == \"train\"].copy()\n",
        "val_df   = df[df[\"split\"] == \"val\"].copy()\n",
        "test_df  = df[df[\"split\"] == \"test\"].copy()\n",
        "\n",
        "train_csv = os.path.join(OUT_SPLIT_DIR, \"train.csv\")\n",
        "val_csv   = os.path.join(OUT_SPLIT_DIR, \"val.csv\")\n",
        "test_csv  = os.path.join(OUT_SPLIT_DIR, \"test.csv\")\n",
        "\n",
        "train_df.to_csv(train_csv, index=False)\n",
        "val_df.to_csv(val_csv, index=False)\n",
        "test_df.to_csv(test_csv, index=False)\n",
        "\n",
        "# Also export path lists\n",
        "train_txt = os.path.join(OUT_SPLIT_DIR, \"train_paths.txt\")\n",
        "val_txt   = os.path.join(OUT_SPLIT_DIR, \"val_paths.txt\")\n",
        "test_txt  = os.path.join(OUT_SPLIT_DIR, \"test_paths.txt\")\n",
        "\n",
        "train_df[\"path\"].to_csv(train_txt, index=False, header=False)\n",
        "val_df[\"path\"].to_csv(val_txt, index=False, header=False)\n",
        "test_df[\"path\"].to_csv(test_txt, index=False, header=False)\n",
        "\n",
        "print(\"Saved splits to:\", OUT_SPLIT_DIR)\n",
        "print(\"Train/Val/Test sizes:\", len(train_df), len(val_df), len(test_df))\n",
        "\n",
        "# Quick distribution checks\n",
        "def dist_report(name, part):\n",
        "    print(f\"\\n=== {name} label_3c distribution ===\")\n",
        "    print(part[\"label_3c\"].value_counts(normalize=False).sort_index())\n",
        "    print(f\"=== {name} label_3c percentages ===\")\n",
        "    print((part[\"label_3c\"].value_counts(normalize=True).sort_index() * 100).round(2))\n",
        "\n",
        "dist_report(\"TRAIN\", train_df)\n",
        "dist_report(\"VAL\", val_df)\n",
        "dist_report(\"TEST\", test_df)\n",
        "\n",
        "print(\"\\n=== Split counts per video ===\")\n",
        "print(df.groupby([\"source_video\", \"split\"]).size().unstack(fill_value=0).sort_index())\n",
        "\n",
        "# Ensure no overlap\n",
        "assert set(train_df[\"file\"]).isdisjoint(set(val_df[\"file\"]))\n",
        "assert set(train_df[\"file\"]).isdisjoint(set(test_df[\"file\"]))\n",
        "assert set(val_df[\"file\"]).isdisjoint(set(test_df[\"file\"]))\n",
        "print(\"\\nNo file overlap across splits: OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odRqGGbHXpeB",
        "outputId": "1a684278-3d32-4f10-e475-edc1fe79cffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved splits to: /content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs/_index_3class/splits_chunked\n",
            "Train/Val/Test sizes: 4563 648 648\n",
            "\n",
            "=== TRAIN label_3c distribution ===\n",
            "label_3c\n",
            "0    1323\n",
            "1    2133\n",
            "2    1107\n",
            "Name: count, dtype: int64\n",
            "=== TRAIN label_3c percentages ===\n",
            "label_3c\n",
            "0    28.99\n",
            "1    46.75\n",
            "2    24.26\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "=== VAL label_3c distribution ===\n",
            "label_3c\n",
            "0    157\n",
            "1    331\n",
            "2    160\n",
            "Name: count, dtype: int64\n",
            "=== VAL label_3c percentages ===\n",
            "label_3c\n",
            "0    24.23\n",
            "1    51.08\n",
            "2    24.69\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "=== TEST label_3c distribution ===\n",
            "label_3c\n",
            "0    268\n",
            "1    262\n",
            "2    118\n",
            "Name: count, dtype: int64\n",
            "=== TEST label_3c percentages ===\n",
            "label_3c\n",
            "0    41.36\n",
            "1    40.43\n",
            "2    18.21\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "=== Split counts per video ===\n",
            "split         test  train  val\n",
            "source_video                  \n",
            "1               54    258   54\n",
            "2              216   1641  216\n",
            "3               54    361   54\n",
            "4               54    326   54\n",
            "5               54    379   54\n",
            "6              108   1098  162\n",
            "7              108    500   54\n",
            "\n",
            "No file overlap across splits: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric\n",
        "print(\"torch_geometric:\", torch_geometric.__version__)\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "print(\"PyG Data import OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dGqG3TWLV7l",
        "outputId": "99f444fc-d5f4-4ce5-a7d3-2a0aa2648d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch_geometric: 2.7.0\n",
            "PyG Data import OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "from dataclasses import dataclass\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "from torch_geometric.nn import GINEConv, GlobalAttention, LayerNorm\n"
      ],
      "metadata": {
        "id": "CFrf5sonLV-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: mapping/caches changed -> delete old cache once before running\n",
        "import shutil\n",
        "if os.path.exists(CACHE_ROOT):\n",
        "    shutil.rmtree(CACHE_ROOT)\n",
        "os.makedirs(CACHE_ROOT, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "fFloNWNKxaUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "\n",
        "# -----------------------------\n",
        "# New system constants (NO GLOVES)\n",
        "# edge_type ids must be:\n",
        "#   0: self-loop\n",
        "#   1: wear_ppe (person->helmet/vest)\n",
        "#   2: near_machine (person->machine)  edge_attr = proximity in [0,1]\n",
        "# -----------------------------\n",
        "EDGE_SELF_LOOP    = 0\n",
        "EDGE_WEAR_PPE     = 1\n",
        "EDGE_NEAR_MACHINE = 2\n",
        "ALLOWED_EDGE_IDS  = {EDGE_SELF_LOOP, EDGE_WEAR_PPE, EDGE_NEAR_MACHINE}\n",
        "\n",
        "\n",
        "def coerce_edge_attr(edge_attr, E: int, jpath: str):\n",
        "    \"\"\"\n",
        "    Ensure edge_attr is list-of-lists with shape [E, 1].\n",
        "    Accepts:\n",
        "      - [[v], [v], ...]\n",
        "      - [v, v, ...]  -> converted to [[v], ...]\n",
        "      - [] if E==0\n",
        "    \"\"\"\n",
        "    if E == 0:\n",
        "        return []\n",
        "\n",
        "    if edge_attr is None:\n",
        "        raise ValueError(f\"edge_attr is None but E>0 in {jpath}\")\n",
        "\n",
        "    if isinstance(edge_attr, list) and len(edge_attr) == E:\n",
        "        # Case A: already list-of-lists\n",
        "        if all(isinstance(a, (list, tuple)) for a in edge_attr):\n",
        "            out = []\n",
        "            for a in edge_attr:\n",
        "                if len(a) < 1:\n",
        "                    out.append([0.0])\n",
        "                else:\n",
        "                    out.append([float(a[0])])\n",
        "            return out\n",
        "\n",
        "        # Case B: flat list [v, v, ...]\n",
        "        if all(isinstance(a, (int, float)) for a in edge_attr):\n",
        "            return [[float(a)] for a in edge_attr]\n",
        "\n",
        "    raise ValueError(\n",
        "        f\"edge_attr format unexpected in {jpath}. \"\n",
        "        f\"Expected len==E ({E}) and either list-of-lists [[v],..] or flat [v,..]. \"\n",
        "        f\"Got type={type(edge_attr).__name__}, len={len(edge_attr) if isinstance(edge_attr, list) else 'NA'}\"\n",
        "    )\n",
        "\n",
        "\n",
        "def load_or_build_video2id(split_csv: str, processed_dir: str) -> dict:\n",
        "    \"\"\"\n",
        "    Build a consistent mapping source_video(str) -> small int id [0..V-1]\n",
        "    shared across train/val/test by scanning CSVs in the same folder.\n",
        "\n",
        "    Saved to: processed_dir/video2id.json\n",
        "    \"\"\"\n",
        "    os.makedirs(processed_dir, exist_ok=True)\n",
        "    map_path = os.path.join(processed_dir, \"video2id.json\")\n",
        "\n",
        "    if os.path.exists(map_path):\n",
        "        with open(map_path, \"r\") as f:\n",
        "            video2id = json.load(f)\n",
        "        # json keys are str, values may come as int already; ensure int\n",
        "        return {str(k): int(v) for k, v in video2id.items()}\n",
        "\n",
        "    split_dir = os.path.dirname(split_csv)\n",
        "\n",
        "    # Prefer the canonical split files if present; otherwise fall back to all csv in folder\n",
        "    preferred = [os.path.join(split_dir, n) for n in [\"train.csv\", \"val.csv\", \"test.csv\"]]\n",
        "    csvs = [p for p in preferred if os.path.exists(p)]\n",
        "    if not csvs:\n",
        "        csvs = sorted(glob.glob(os.path.join(split_dir, \"*.csv\")))\n",
        "\n",
        "    videos = set()\n",
        "    for cp in csvs:\n",
        "        try:\n",
        "            tmp = pd.read_csv(cp, usecols=[\"source_video\"])\n",
        "            videos.update(tmp[\"source_video\"].astype(str).tolist())\n",
        "        except Exception:\n",
        "            # source_video column missing or unreadable -> ignore\n",
        "            pass\n",
        "\n",
        "    if not videos:\n",
        "        videos = {\"unknown\"}\n",
        "\n",
        "    videos = sorted(videos)\n",
        "    video2id = {v: i for i, v in enumerate(videos)}  # 0..V-1 deterministic\n",
        "\n",
        "    with open(map_path, \"w\") as f:\n",
        "        json.dump(video2id, f, indent=2)\n",
        "\n",
        "    return video2id\n",
        "\n",
        "\n",
        "class GraphJsonInMemoryDataset(InMemoryDataset):\n",
        "    \"\"\"\n",
        "    Reads graphs from JSON paths listed in a split CSV and builds PyG InMemoryDataset.\n",
        "\n",
        "    Expected CSV columns:\n",
        "      - path (json full path)\n",
        "      - label_3c (0/1/2)\n",
        "    Optional columns used if present:\n",
        "      - source_video\n",
        "      - frame_id\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        root: str,\n",
        "        split_csv: str,\n",
        "        split_name: str,\n",
        "        transform=None,\n",
        "        pre_transform=None,\n",
        "    ):\n",
        "        self.split_csv = split_csv\n",
        "        self.split_name = split_name\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "\n",
        "        self.data, self.slices = self._safe_load_or_rebuild(self.processed_paths[0])\n",
        "\n",
        "    def _safe_load_or_rebuild(self, path: str):\n",
        "        \"\"\"\n",
        "        PyTorch 2.6 changed torch.load default weights_only=True.\n",
        "        PyG Data objects in cache may require weights_only=False.\n",
        "\n",
        "        Strategy:\n",
        "          1) Try weights_only=True\n",
        "          2) If fails, try weights_only=False (ONLY for trusted local cache)\n",
        "          3) If still fails, delete cache and rebuild by calling process()\n",
        "        \"\"\"\n",
        "        if not os.path.exists(path):\n",
        "            # Defensive: if processed file missing, build it now\n",
        "            self.process()\n",
        "            return torch.load(path, weights_only=False)\n",
        "\n",
        "        try:\n",
        "            return torch.load(path)  # weights_only defaults to True in torch 2.6\n",
        "        except Exception as e_safe:\n",
        "            try:\n",
        "                return torch.load(path, weights_only=False)\n",
        "            except Exception as e_full:\n",
        "                print(f\"[WARN] Cache load failed for {path}. Rebuilding cache...\")\n",
        "                print(f\"  - safe load error: {type(e_safe).__name__}: {str(e_safe)[:200]}\")\n",
        "                print(f\"  - full load error: {type(e_full).__name__}: {str(e_full)[:200]}\")\n",
        "\n",
        "                try:\n",
        "                    os.remove(path)\n",
        "                except OSError:\n",
        "                    pass\n",
        "\n",
        "                self.process()\n",
        "                return torch.load(path, weights_only=False)\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [f\"data_{self.split_name}.pt\"]\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return []\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        df = pd.read_csv(self.split_csv)\n",
        "\n",
        "        assert \"path\" in df.columns, \"split CSV must contain 'path' column\"\n",
        "        assert \"label_3c\" in df.columns, \"split CSV must contain 'label_3c' column\"\n",
        "\n",
        "        # Sanity: label_3c should be {0,1,2}\n",
        "        bad_labels = set(df[\"label_3c\"].unique()) - {0, 1, 2}\n",
        "        if bad_labels:\n",
        "            raise ValueError(f\"Unexpected label_3c values in {self.split_csv}: {sorted(bad_labels)}\")\n",
        "\n",
        "        has_source_video_col = (\"source_video\" in df.columns)\n",
        "        has_frame_id_col = (\"frame_id\" in df.columns)\n",
        "\n",
        "        # ---- DÜZELTME B: global, small, consistent ids 0..V-1 ----\n",
        "        video2id = load_or_build_video2id(self.split_csv, self.processed_dir)\n",
        "        # (İsterseniz model cfg için: num_videos = len(video2id))\n",
        "\n",
        "        data_list = []\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            jpath = str(row[\"path\"])\n",
        "            y = int(row[\"label_3c\"])\n",
        "\n",
        "            with open(jpath, \"r\") as f:\n",
        "                g = json.load(f)\n",
        "\n",
        "            node_features = g.get(\"node_features\", [])\n",
        "            edge_index = g.get(\"edge_index\", [[], []])\n",
        "            edge_type = g.get(\"edge_type\", [])\n",
        "            edge_attr = g.get(\"edge_attr\", [])\n",
        "\n",
        "            # Basic sanity\n",
        "            if not isinstance(edge_index, list) or len(edge_index) != 2:\n",
        "                raise ValueError(f\"Invalid edge_index format in: {jpath}\")\n",
        "\n",
        "            if len(node_features) == 0:\n",
        "                raise ValueError(f\"Empty node_features in {jpath} (graph has no nodes).\")\n",
        "\n",
        "            src_list = edge_index[0]\n",
        "            dst_list = edge_index[1]\n",
        "            if len(src_list) != len(dst_list):\n",
        "                raise ValueError(\n",
        "                    f\"edge_index src/dst len mismatch in {jpath}: {len(src_list)} vs {len(dst_list)}\"\n",
        "                )\n",
        "\n",
        "            E = len(src_list)\n",
        "\n",
        "            if len(edge_type) != E:\n",
        "                raise ValueError(f\"edge_type len mismatch in {jpath}: {len(edge_type)} vs E={E}\")\n",
        "\n",
        "            extra_edge_ids = set(edge_type) - ALLOWED_EDGE_IDS\n",
        "            if extra_edge_ids:\n",
        "                raise ValueError(\n",
        "                    f\"Unexpected edge_type ids {sorted(extra_edge_ids)} in {jpath} \"\n",
        "                    f\"(expected {sorted(ALLOWED_EDGE_IDS)})\"\n",
        "                )\n",
        "\n",
        "            edge_attr = coerce_edge_attr(edge_attr, E, jpath)\n",
        "\n",
        "            # Build tensors\n",
        "            x = torch.tensor(node_features, dtype=torch.float32)          # [N, F]\n",
        "            edge_index_t = torch.tensor(edge_index, dtype=torch.long)     # [2, E]\n",
        "            edge_type_t = torch.tensor(edge_type, dtype=torch.long)       # [E]\n",
        "            edge_attr_t = torch.tensor(edge_attr, dtype=torch.float32)    # [E, 1]\n",
        "            y_t = torch.tensor([y], dtype=torch.long)                     # [1]\n",
        "\n",
        "            if x.dim() != 2 or x.size(1) < 10:\n",
        "                raise ValueError(f\"node_features expected [N,>=10], got {list(x.shape)} in {jpath}\")\n",
        "\n",
        "            if E > 0:\n",
        "                if edge_attr_t.dim() != 2 or edge_attr_t.size(0) != E or edge_attr_t.size(1) != 1:\n",
        "                    raise ValueError(f\"edge_attr expected [E,1], got {list(edge_attr_t.shape)} in {jpath}\")\n",
        "\n",
        "            N = x.size(0)\n",
        "            if E > 0:\n",
        "                if edge_index_t.min().item() < 0 or edge_index_t.max().item() >= N:\n",
        "                    raise ValueError(\n",
        "                        f\"edge_index has out-of-range node ids in {jpath}. N={N}, max={edge_index_t.max().item()}\"\n",
        "                    )\n",
        "\n",
        "            # machine_subclass_id: [-1 for non-machine, 0..9 for machines]\n",
        "            machine_subclass_id = x[:, 9].to(torch.long)\n",
        "\n",
        "            # Metadata\n",
        "            source_video = (row[\"source_video\"] if has_source_video_col else g.get(\"source_video\", \"unknown\"))\n",
        "            frame_id = int(row[\"frame_id\"]) if has_frame_id_col else int(g.get(\"frame_id\", -1))\n",
        "\n",
        "            # ---- DÜZELTME B: map to 0..V-1 ----\n",
        "            source_video_id = video2id.get(str(source_video), video2id.get(\"unknown\", 0))\n",
        "\n",
        "            data = Data(\n",
        "                x=x,\n",
        "                edge_index=edge_index_t,\n",
        "                edge_type=edge_type_t,\n",
        "                edge_attr=edge_attr_t,\n",
        "                y=y_t,\n",
        "            )\n",
        "\n",
        "            data.machine_subclass_id = machine_subclass_id\n",
        "            # keep old attribute name for compatibility with your prints\n",
        "            data.source_video = torch.tensor([source_video_id], dtype=torch.long)\n",
        "            data.source_video_id = torch.tensor([source_video_id], dtype=torch.long)\n",
        "            data.frame_id = torch.tensor([frame_id], dtype=torch.long)\n",
        "\n",
        "            data_list.append(data)\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(d) for d in data_list]\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "\n",
        "# ---- Usage: create datasets for each split (NEW SYSTEM PATHS) ----\n",
        "DATA_DIR = \"/content/drive/Othercomputers/Dizüstü Bilgisayarım/Google drive Masaustu/0-PPE/0-Data Factory outputs\"\n",
        "INDEX_DIR = os.path.join(DATA_DIR, \"_index_3class\")\n",
        "SPLIT_DIR = os.path.join(INDEX_DIR, \"splits_chunked\")\n",
        "\n",
        "train_csv = os.path.join(SPLIT_DIR, \"train.csv\")\n",
        "val_csv   = os.path.join(SPLIT_DIR, \"val.csv\")\n",
        "test_csv  = os.path.join(SPLIT_DIR, \"test.csv\")\n",
        "\n",
        "CACHE_ROOT = os.path.join(SPLIT_DIR, \"_pyg_cache\")\n",
        "os.makedirs(CACHE_ROOT, exist_ok=True)\n",
        "\n",
        "# IMPORTANT: mapping/caches changed -> delete old cache once before running\n",
        "# import shutil\n",
        "# if os.path.exists(CACHE_ROOT):\n",
        "#     shutil.rmtree(CACHE_ROOT)\n",
        "# os.makedirs(CACHE_ROOT, exist_ok=True)\n",
        "\n",
        "train_ds = GraphJsonInMemoryDataset(root=CACHE_ROOT, split_csv=train_csv, split_name=\"train\")\n",
        "val_ds   = GraphJsonInMemoryDataset(root=CACHE_ROOT, split_csv=val_csv,   split_name=\"val\")\n",
        "test_ds  = GraphJsonInMemoryDataset(root=CACHE_ROOT, split_csv=test_csv,  split_name=\"test\")\n",
        "\n",
        "print(\"Datasets loaded:\")\n",
        "print(\"  train:\", len(train_ds))\n",
        "print(\"  val  :\", len(val_ds))\n",
        "print(\"  test :\", len(test_ds))\n",
        "\n",
        "d0 = train_ds[0]\n",
        "print(\"\\nSample[0] tensors:\")\n",
        "print(\"  x:\", d0.x.shape, d0.x.dtype)\n",
        "print(\"  edge_index:\", d0.edge_index.shape, d0.edge_index.dtype)\n",
        "print(\"  edge_type:\", d0.edge_type.shape, d0.edge_type.dtype)\n",
        "print(\"  edge_attr:\", d0.edge_attr.shape, d0.edge_attr.dtype)\n",
        "print(\"  y:\", d0.y, d0.y.dtype)\n",
        "print(\"  machine_subclass_id:\", d0.machine_subclass_id.shape, d0.machine_subclass_id.dtype)\n",
        "print(\"  source_video_id:\", d0.source_video.item(), \"frame_id:\", d0.frame_id.item())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyD9x7khLZpg",
        "outputId": "d24a7d1c-eac7-4608-bf7a-15602c994084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n",
            "Processing...\n",
            "Done!\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets loaded:\n",
            "  train: 4563\n",
            "  val  : 648\n",
            "  test : 648\n",
            "\n",
            "Sample[0] tensors:\n",
            "  x: torch.Size([3, 10]) torch.float32\n",
            "  edge_index: torch.Size([2, 5]) torch.int64\n",
            "  edge_type: torch.Size([5]) torch.int64\n",
            "  edge_attr: torch.Size([5, 1]) torch.float32\n",
            "  y: tensor([1]) torch.int64\n",
            "  machine_subclass_id: torch.Size([3]) torch.int64\n",
            "  source_video_id: 0 frame_id: 4920\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_Cs82pK8lbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5LZ153i68liw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0MyniXwc8l0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_QwT_CA8l4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfu7Ip6R8l71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hBgRckvMLZxL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}